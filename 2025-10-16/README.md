# AI应用开发实践：从模型到智能体

## 0. 开场：AI浪潮下的开发者新机遇 (5分钟)

*   **引子**：从“Hello, World!”到“Hello, AI!”，回顾软件开发范式的变迁。
*   **现状**：为什么现在是学习AI应用开发的最佳时机？（模型能力增强、社区活跃、工具链成熟）
*   **目标**：本次分享将带你了解AI应用开发的核心模式，让你能亲手将大语言模型（LLM）从一个“聪明的聊天机器人”变为一个能解决实际问题的“智能助手”。

## 1. 核心引擎：重新认识我们的大语言模型 (LLM) (10分钟)

*   **它是什么？**：用一个简单的比喻理解LLM——一个基于海量知识训练出来的、强大的“文本续写”引擎。
*   **它能做什么？（开箱即用的能力）**
    *   文本生成：写文章、写代码
    *   知识问答：回答常识性问题
    *   内容总结：提炼文章核心观点
    *   语言翻译：跨语言沟通
*   **它的局限性？（为什么我们不能只用LLM）**
    *   **知识的局限**：知识有截止日期，无法获取实时信息（例如：今天天气如何？）。
    *   **事实的局限**：可能会“一本正经地胡说八道”（幻觉问题）。
    *   **能力的局限**：无法与外部世界交互（例如：无法帮你订票、无法查询数据库）。
*   **主流模型概览**：简单介绍几个主流模型（如GPT系列、Claude系列、Llama系列），让大家有个基本认识。

## 2. 模式一：给模型一本“开卷考试”的书 —— RAG (15分钟)

*   **面临的问题**：“我的模型不知道我们公司的内部规定，怎么办？”
*   **解决方案：RAG（检索增强生成）**
    *   **核心思想**：不要求模型“记住”所有知识，而是让它在回答问题前，先去一个指定的知识库里“查找”相关资料，然后基于查到的资料来回答。
    *   **工作流程（三步走）**
        1.  **知识预处理**：将你的文档（如PDF、Markdown）切块、向量化，存入“知识库”（向量数据库）。
        2.  **智能检索**：当用户提问时，将问题同样向量化，去知识库中找到最相关的几个知识片段。
        3.  **增强生成**：将用户的问题和检索到的知识片段一起发给LLM，让它“参考”这些资料生成最终答案。
*   **适用场景**：企业知识库问答、智能客服、文档助手。
*   **小结**：RAG解决了模型**知识局限**的问题，让它能基于私有、实时的信息进行回答。

## 3. 模式二：给模型一双“万能的手” —— Function Calling (15分钟)

*   **面临的问题**：“我的模型只能聊天，不能帮我做事，怎么办？”
*   **解决方案：Function Calling（函数调用）**
    *   **核心思想**：让LLM成为一个“指挥官”，它能理解你的意图，然后调用你预先定义好的外部工具（函数/API）去执行任务。
    *   **工作流程（四步走）**
        1.  **工具声明**：向LLM“注册”你的工具清单，告诉它每个工具能做什么、需要什么参数（例如 `query_stock_price(code)`)。
        2.  **意图识别**：LLM分析用户输入，判断是否需要使用工具，以及使用哪个工具和传入什么参数。
        3.  **外部执行**：你的代码根据LLM的指令，执行相应的函数。
        4.  **结果整合**：将函数执行的结果返回给LLM，由它整理成自然语言回复给用户。
*   **适用场景**：智能家居控制、连接内部API、执行数据库查询、自动化工作流。
*   **小结**：Function Calling解决了模型**能力局限**的问题，让它能与外部世界交互，执行实际操作。

## 4. 演进：当模型拥有“大脑”和“手脚” —— Agent (10分钟)

*   **什么是Agent？**：一个能够自主思考、规划、并利用多种工具（如RAG、Function Calling）来达成复杂目标的智能体。
*   **核心循环**：`思考 -> 行动 -> 观察 -> 再次思考...` 直到任务完成。
*   **面临的挑战**：工具越来越多，模型也越来越多，如何让它们之间高效、标准地协作？这就引出了我们今天重点要介绍的协议。

## 5. 未来：AI世界的“普通话” —— Model Context Protocol (MCP) (20分钟)

*   **要解决的问题**：目前工具调用缺乏统一标准，如同“方言”林立，每个模型或框架都有自己的实现，导致工具无法复用，开发效率低下。
*   **MCP是什么？**：一个为AI应用连接外部系统而设计的**标准开源协议**。
    *   **核心目标**：让任何模型都能方便地发现、理解和调用任何遵循该协议的工具。
    *   **打个比方**：MCP就像是AI工具领域的“USB接口”或“RESTful API”，提供了一套统一的规范。
*   **核心优势**：
    *   **标准化**：统一工具的发现和调用流程。
    *   **可复用**：一次开发工具，处处可用。
    *   **可组合**：轻松将多个工具组合成强大的工作流。
*   **实践案例**：以`eaip mcp`路由为例，展示如何通过MCP协议，让企业内部的各种API服务，快速变成可供AI调用的“工具”。

## 6. Demo演示 (5分钟)

*   现场演示一个简单的应用，通过MCP连接LLM和一个自定义工具，完成一个具体任务。

## 7. 总结与Q&A (5分钟)

*   **回顾**：LLM (核心) -> RAG (赋予知识) -> Function Calling (赋予工具) -> Agent (赋予大脑) -> MCP (赋予标准)。
*   **给初学者的建议**：AI应用开发的重点不在于创造模型，而在于如何“驾驭”模型，通过组合工具和数据来创造价值。
*   **开放问答**
