### AI应用开发实践：从模型到智能体（演讲稿）

**(准备)**

*   **风格**：轻松、有活力，多用比喻，少用生僻术语。
*   **对象**：初级开发工程师。
*   **目标**：听完后，不仅理解几种主流AI开发模式，更能激发动手尝试的兴趣。

---

#### **幻灯片 1: 标题页**

*   **标题**: AI应用开发实践：从模型到智能体
*   **副标题**: 赋予代码“思考”的能力
*   **讲者**: [你的名字]
*   **日期**: 2025年10月16日

**(演讲开始)**

---

#### **幻灯片 2: 开场 - AI浪潮下的开发者新机遇**

*   **内容**: 一张左边是`console.log("Hello, World!");`代码，右边是AI对话截图的对比图。

**(讲者台词)**

“大家好，欢迎来到今天的分享会。我是[你的名字]。”

“我们先来看一张图。左边这行代码，`Hello, World!`，可以说是我们每个程序员梦开始的地方。它代表了过去几十年里，我们与机器沟通的方式：精确、具体、一行一行地告诉它做什么。”

“而右边，是我们现在越来越熟悉的AI对话。我们用自然语言，模糊地、甚至带点感情地跟它交流，它就能理解我们的意图。这不仅仅是交互方式的改变，它预示着一个全新的软件开发范式正在到来。”

**(切换PPT)**

---

#### **幻灯片 3: 为什么是现在？**

*   **内容**: 三个图标，分别代表“模型能力增强”、“社区活跃”、“工具链成熟”。

**(讲者台词)**

“可能有人会问，AI喊了这么多年，为什么现在是开发者入局的最佳时机？”

“首先，**模型能力**出现了质的飞跃。像GPT-4、Claude 3这些模型，它们的理解和推理能力已经强大到可以作为我们日常开发的得力助手。”

“其次，**社区空前活跃**。无论你遇到什么问题，几乎都能在开源社区找到答案、工具或者灵感。”

“最后，也是最重要的，**工具链越来越成熟**。我们不再需要从零开始研究算法，而是可以像搭乐高一样，利用现成的工具快速构建出强大的AI应用。”

“所以，今天分享的目标很简单：带大家了解当前最主流的几种AI应用开发模式，让你能亲手把一个‘聪明的聊天机器人’，升级成一个能解决实际问题的‘智能助手’。我们不谈复杂的数学，只谈实践。”

**(切换PPT)**

---

#### **幻灯片 4: 核心引擎 - 重新认识我们的大语言模型 (LLM)**

*   **内容**: 一个大脑的图标，周围环绕着“文本生成”、“知识问答”、“内容总结”、“语言翻译”等关键词。

**(讲者台词)**

“好，让我们从核心开始——大语言模型，也就是LLM。大家可以把它想象成一个**超级‘文本续写’引擎**。”

“你给它任何一段文字，它都能根据自己从海量数据中学到的‘知识’，预测出最可能接在后面的内容。我们平时用到的文本生成、问答、总结、翻译，本质上都是这个核心能力的延伸。”

“为了让大家有个更直观的感受，我们来看一下市面上几个主流模型的对比。”

**(切换PPT)**

---

#### **幻灯片 5: 主流模型能力对比**

*   **内容**: 一个清晰的Markdown表格。

**(讲者台词)**

“这张表对比了三个目前最顶尖的模型：OpenAI的GPT-4o，Anthropic的Claude 3 Opus，以及Meta的开源模型Llama 3。”

| 特性 | GPT-4o (OpenAI) | Claude 3 Opus (Anthropic) | Llama 3 70B (Meta) |
| :--- | :--- | :--- | :--- |
| **上下文窗口** | 128K tokens | **200K tokens** | 8K tokens |
| **核心优势** | 综合能力强，多模态 | **长文本处理**，逻辑推理 | 开源，可本地部署 |
| **函数调用** | **原生支持，功能强大** | 原生支持，持续优化中 | 社区方案，需额外实现 |
| **响应速度** | **非常快** | 较快 | 快（取决于硬件） |
| **成本** | 中等（$） | 较高（$$） | 硬件成本（$$$） |

“大家注意几个关键点：”
“**上下文窗口**：这决定了我们一次能给模型‘喂’多少信息。Claude 3 Opus在这方面是王者，200K的窗口意味着它可以一次性读完一本中篇小说，这对RAG应用尤其重要。”
“**函数调用**：GPT系列在这方面起步最早，支持最完善，是我们今天讲的Function Calling模式的首选。其他模型也都在快速跟上。”
“**成本与开源**：Llama 3是开源的，意味着你可以在自己的服务器上部署，保证数据私密性，但需要承担硬件和维护成本。而GPT和Claude则提供了按量付费的API，开箱即用。”

“总的来说，没有‘最好’的模型，只有‘最合适’的模型。技术选型时，我们需要根据应用场景、预算和对数据隐私的要求来综合判断。”

**(切换PPT)**

---

#### **幻灯片 6: LLM的三大“局限性”**

*   **内容**: 三个场景配上问号。
    1.  日历图标 + “今天天气如何？”
    2.  公司Logo + “我们公司最新的报销政策是什么？”
    3.  飞机图标 + “帮我订一张去北京的机票。”

**(讲者台词)**

“了解了模型的能力，我们再回来看它的三大局限：**知识局限、事实局限、能力局限**。这三个局限，正是我们开发者大展身手的地方。接下来，我们会逐一介绍如何用不同的开发模式，为模型‘排忧解难’。”

**(切换PPT)**

---

#### **幻灯片 7: 模式一 - RAG：给模型一本“开卷考试”的书**

*   **内容**: 一个流程图：用户问题 -> [**检索器** 在知识库里查找] -> [**生成器** 参考资料回答] -> 最终答案。

**(讲者台词)**

“我们先解决‘事实局限’，如何让模型基于我们公司的内部知识来回答问题？”

“答案就是**RAG**，让模型‘**开卷考试**’。我们不要求模型‘背’下所有内部文档，而是当用户提问时，先去我们的‘资料库’里查找相关原文，然后把问题和资料一起交给模型，让它参考作答。”

“这样，模型回答的内容就会严格基于我们提供的资料，大大减少了‘幻觉’。”

**(切换PPT)**

---

#### **幻灯片 8: RAG实战案例：电商智能客服**

*   **内容**: 一个电商客服对话截图。用户问：“你们的XX型号耳机支持防水吗？退货政策是怎样的？” AI客服精准地引用了产品手册和退货政策作答。

**(讲者台词)**

“我们来看一个真实的案例：电商智能客服。”

“**痛点**：传统客服每天要回答大量重复问题，比如‘这个商品包邮吗？’、‘7天无理由退货怎么操作？’，不仅效率低，而且高峰期用户等待时间长。”

“**RAG解决方案**：”
1.  “**构建知识库**：我们将所有的商品详情页、SKU参数、售后服务条款、退换货政策等文档，全部处理后存入一个向量数据库。”
2.  “**检索与生成**：当用户提问，比如‘XX耳机防水等级和退货政策’，系统会先检索到‘XX耳机说明书’中关于IPX7防水的段落，和‘售后服务’文档中关于30天退货政策的条款。”
3.  “**整合答案**：最后，LLM会把这些碎片化的信息，整合成一段通顺、完整的回答呈现给用户。”

“**效果**：通过这种方式，80%的常见问题都可以由AI客服自动、准确地回答，人工客服则可以解放出来，专注于处理更复杂的售后纠纷，整体服务质量和用户满意度都得到了提升。”

**(切换PPT)**

---

#### **幻灯片 9: 模式二 - Function Calling：给模型一双“万能的手”**

*   **内容**: 一个流程图：用户说“查查天气” -> LLM识别意图，输出`{"tool": "query_weather", "city": "北京"}` -> 你的代码执行这个函数 -> 结果返回给LLM -> LLM生成自然语言回答。

**(讲者台词)**

“好，解决了知识问题，我们再来解决‘能力’问题：如何让模型有手有脚，能干活？”

“这就是**Function Calling**，函数调用。核心思想是让LLM当一个‘**指挥官**’，它负责理解用户意图并下达指令，而我们开发者，则提供具体的工具（函数/API）来执行这些指令。”

**(切换PPT)**

---

#### **幻灯片 10: Function Calling实战案例：会议智能助理**

*   **内容**: 一个日历应用截图。用户在聊天框输入：“帮我约一个明天下午2点和张三的会议，主题是项目复盘，记得预定会议室A。” 系统自动在日历上创建了一个事件。

**(讲者台词)**

“再来看一个Function Calling的案例：会议智能助理。”

“**痛点**：在企业内部，预定一个会议通常需要多个步骤：打开日历、检查参会人是否有空、找一个可用的会议室、发送会议邀请... 非常繁琐。”

“**Function Calling解决方案**：”
1.  “**定义工具集**：我们为LLM提供一组原子化的API工具，比如：`check_calendar(person, time)`（检查某人是否有空）、`find_available_room(time)`（查找可用会议室）、`create_meeting(participants, topic, time, location)`（创建会议）。”
2.  “**智能解析**：当用户输入‘帮我约个会...’，LLM会像一个真人助理一样，从这段话里解析出所有关键信息：`participants=['我', '张三']`, `time='明天下午2点'`, `topic='项目复盘'`, `location='会议室A'`。”
3.  “**执行与反馈**：LLM随后会生成调用`create_meeting`工具的指令。我们的后端代码执行这个函数，成功在日历系统里创建会议后，再把成功的结果返回给LLM。最后，LLM回复用户：‘好的，会议已预定成功。’”

“**效果**：用户通过一句自然语言，就完成了一个过去需要点击鼠标好几次的复杂工作流，这就是Function Calling的价值所在——**用对话驱动业务流程**。”

**(切换PPT)**

---

#### **幻灯片 11: 演进 - Agent：当模型拥有“大脑”和“手脚”**

*   **内容**: 一个循环图：`思考 -> 规划 -> 行动(调用工具) -> 观察(得到结果) -> 再次思考...`

**(讲者台词)**

“当我们把RAG（知识）和Function Calling（工具）结合起来，再赋予模型一个‘思考和规划’的能力，一个更高级的概念就诞生了——**Agent**，智能体。”

“Agent不再是简单的一问一答，它能为了一个复杂目标，自主地**拆解任务、制定计划、调用多种工具、并根据上一步的结果来动态调整下一步的行动**。”

“我们还是用那个出差规划的例子来深入看一下。”

**(切换PPT)**

---

#### **幻灯片 12: Agent案例深度解析：AI旅行助手**

*   **内容**: 一个任务拆解的树状图。
    *   **总目标**: “规划明天去北京的出差行程”
        *   **子任务1**: 获取交通信息 -> 调用 `search_flights('北京')`
        *   **子任务2**: 获取天气信息 -> 调用 `query_weather('北京')`
        *   **子任务3**: 查找住宿 -> 调用 `search_hotels(area='国贸')`
        *   **子任务4**: 整理并发送报告 -> 调用 `send_email(...)`

**(讲者台词)**

“用户只说了一句笼统的话：‘帮我规划一下明天去北京的出差行程，订好票，查好天气，然后把结果发邮件给我。’”

“一个成熟的Agent会这样做：”
1.  “**思考与规划 (Step 1)**：它首先会分析，‘规划行程’这个目标太大了，需要拆解。它会规划出几个步骤：先查航班，再查天气，然后根据航班信息和用户偏好（比如住在国贸附近）查酒店，最后汇总所有信息发邮件。”
2.  “**行动与观察 (Step 2)**：它会依次调用`search_flights`和`query_weather`工具，并拿到返回结果，比如‘查询到CA123航班，明天北京天气晴朗’。”
3.  “**再次思考与行动 (Step 3)**：它会基于上一步的结果继续执行。‘天气不错，航班时间也确定了，现在可以查酒店了’。于是它调用`search_hotels`工具。”
4.  “**最终行动 (Step 4)**：在收集到所有必要信息后，它会调用`send_email`工具，将一个结构清晰的行程单发送到你的邮箱。”

“这就是Agent和简单Function Calling的核心区别：**Agent具备了自主规划和多步推理的能力**，能完成更复杂的、需要连续操作的任务。但这也引出了一个新问题...”

**(切换PPT)**

---

#### **幻灯片 13: 未来 - MCP：AI世界的“普通话”**

*   **内容**: 左边是各种不同形状的插头（代表私有工具协议），右边是一个统一的USB-C接口（代表MCP）。

**(讲者台词)**

“问题就是，现在每个模型、每个框架，它们定义和调用工具的方式都不一样，就像是各种‘方言’。我为GPT写的工具，给Claude用可能就得改。这极大地阻碍了工具的复用和生态的发展。”

“为了解决这个问题，**Model Context Protocol (MCP)** 应运而生。它的目标，就是成为AI工具领域的‘**普通话**’，或者说是‘**USB-C接口**’。”

“MCP是一个**标准化的开源协议**。它定义了一套统一的规范，让任何模型，都能方便地发现、理解和调用任何遵循这套规范的工具。”

“它的好处是显而易见的：**标准化、可复用、可组合**。开发者只需要写一次工具，就能接入到所有支持MCP的模型和应用中，极大地提升了开发效率。”

“比如我们内部的`eaip mcp`路由，就是基于这个理念，把企业内部五花八门的API服务，统一封装成符合MCP标准的工具，让AI可以安全、高效地调用。”

**(切换PPT)**

---

#### **幻-灯片 14: Demo演示**

*   **内容**: 屏幕录制或现场操作。

**(讲者台词)**

“说了这么多理论，我们来点实际的。接下来，我将现场演示一个非常简单的应用，它会通过MCP协议，让一个大语言模型调用一个我刚刚写的、用来查询今天日期的自定义工具。”

**(开始演示)**

1.  “首先，大家看，这是一个简单的MCP工具服务器，它暴露了一个叫`get_today_date`的工具。”
2.  “然后，在我们的客户端，我们不需要关心这个工具是怎么实现的，只需要连接到MCP服务器。”
3.  “现在，我向模型提问：‘今天几号？’。注意，模型本身是不知道实时日期的。”
4.  “看，模型通过MCP协议发现了`get_today_date`工具，并决定调用它。我们的服务器收到了调用请求，执行函数，并返回了今天的日期。”
5.  “最终，模型将结果格式化后，告诉我们‘今天是2025年10月16日’。”
6.  “这个过程，完美地展示了模型、协议、工具之间的协作。”

**(演示结束)**

---

#### **幻灯片 15: 总结与Q&A**

*   **内容**: 一条清晰的进化路径图：`LLM (核心) -> RAG (赋予知识) -> Function Calling (赋予工具) -> Agent (赋予大脑) -> MCP (赋予标准)`

**(讲者台词)**

“好了，我们来快速回顾一下今天的旅程。”

“我们从一个基础的**LLM**核心出发，它很聪明，但有局限。”
“通过**RAG**，我们给了它一本‘开卷考试’的书，解决了知识局限。”
“通过**Function Calling**，我们给了它一双‘万能的手’，解决了能力局限。”
“将两者结合，就进化成了能自主规划的**Agent**。”
“最后，为了让生态系统更有序、高效，我们引入了**MCP**，这门AI世界的‘普通话’。”

“对于我们开发者来说，我想传达的最重要的一点是：**AI应用开发的重点，已经从‘创造模型’转向了‘驾驭模型’**。我们的核心竞争力，在于如何巧妙地组合数据和工具，来创造出真正有价值的应用。”

“我的分享就到这里，谢谢大家。现在是Q&A时间，有什么问题欢迎提出。”