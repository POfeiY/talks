### AI应用开发实践：从模型到智能体（演讲稿）

**(准备)**

*   **风格**：轻松、有活力，多用比喻，少用生僻术语。
*   **对象**：初级开发工程师。
*   **目标**：听完后，不仅理解几种主流AI开发模式，更能激发动手尝试的兴趣。

---

#### **幻灯片 1: 标题页**

*   **标题**: AI应用开发实践：从模型到智能体
*   **副标题**: 赋予代码“思考”的能力
*   **讲者**: [你的名字]
*   **日期**: 2025年10月16日

**(演讲开始)**

---

#### **幻灯片 2: 开场 - AI浪潮下的开发者新机遇**

*   **内容**: 一张左边是`console.log("Hello, World!");`代码，右边是AI对话截图的对比图。

**(讲者台词)**

“大家好，欢迎来到今天的分享会。我是[你的名字]。”

“我们先来看一张图。左边这行代码，`Hello, World!`，可以说是我们每个程序员梦开始的地方。它代表了过去几十年里，我们与机器沟通的方式：精确、具体、一行一行地告诉它做什么。”

“而右边，是我们现在越来越熟悉的AI对话。我们用自然语言，模糊地、甚至带点感情地跟它交流，它就能理解我们的意ت图。这不仅仅是交互方式的改变，它预示着一个全新的软件开发范式正在到来。”

**(切换PPT)**

---

#### **幻灯片 3: 为什么是现在？**

*   **内容**: 三个图标，分别代表“模型能力增强”、“社区活跃”、“工具链成熟”。

**(讲者台词)**

“可能有人会问，AI喊了这么多年，为什么现在是开发者入局的最佳时机？”

“首先，**模型能力**出现了质的飞跃。像GPT-4、Claude 3这些模型，它们的理解和推理能力已经强大到可以作为我们日常开发的得力助手。”

“其次，**社区空前活跃**。无论你遇到什么问题，几乎都能在开源社区找到答案、工具或者灵感。”

“最后，也是最重要的，**工具链越来越成熟**。我们不再需要从零开始研究算法，而是可以像搭乐高一样，利用现成的工具快速构建出强大的AI应用。”

“所以，今天分享的目标很简单：带大家了解当前最主流的几种AI应用开发模式，让你能亲手把一个‘聪明的聊天机器人’，升级成一个能解决实际问题的‘智能助手’。我们不谈复杂的数学，只谈实践。”

**(切换PPT)**

---

#### **幻灯片 4: 核心引擎 - 重新认识我们的大语言模型 (LLM)**

*   **内容**: 一个大脑的图标，周围环绕着“文本生成”、“知识问答”、“内容总结”、“语言翻译”等关键词。

**(讲者台词)**

“好，让我们从核心开始——大语言模型，也就是LLM。大家可以把它想象成一个**超级‘文本续写’引擎**。”

“你给它任何一段文字，它都能根据自己从海量数据中学到的‘知识’，预测出最可能接在后面的内容。我们平时用到的文本生成、问答、总结、翻译，本质上都是这个核心能力的延伸。”

“听起来很强大，对吧？但如果我们只把它当成一个‘万事通’来用，很快就会碰壁。”

**(切换PPT)**

---

#### **幻灯片 5: LLM的三大“局限性”**

*   **内容**: 三个场景配上问号。
    1.  日历图标 + “今天天气如何？”
    2.  公司Logo + “我们公司最新的报销政策是什么？”
    3.  飞机图标 + “帮我订一张去北京的机票。”

**(讲者台词)**

“我们来看三个简单的需求。”

“第一个，**知识的局限**。你问它‘今天天气如何？’，它很可能会告诉你它的知识截止到某个日期，无法回答实时信息。因为它是个‘书呆子’，知识都来自训练数据，不会‘上网’。”

“第二个，**事实的局限**。你问它‘我们公司最新的报销政策？’，它大概率会‘一本正经地胡说八道’，编一个看似合理的答案给你。这就是所谓的‘幻觉’。因为它没读过你们公司的内部文档。”

“第三个，**能力的局限**。你让它‘帮我订张机票’，它只能抱歉地告诉你，它只是一个语言模型，没有手脚，无法操作外部世界。”

“这三个局限，正是我们开发者大展身手的地方。接下来，我们会逐一介绍如何用不同的开发模式，为模型‘排忧解难’。”

**(切换PPT)**

---

#### **幻灯片 6: 模式一 - RAG：给模型一本“开卷考试”的书**

*   **内容**: 一个流程图：用户问题 -> [**检索器** 在知识库里查找] -> [**生成器** 参考资料回答] -> 最终答案。

**(讲者台词)**

“我们先解决第二个问题：如何让模型基于我们公司的内部知识来回答问题？”

“答案就是**RAG**，检索增强生成。这个名字听起来很技术，但它的思想非常简单，就是让模型‘**开卷考试**’。”

“我们不要求模型‘背下’所有内部文档，那不现实。相反，我们建一个‘资料库’（也就是向量数据库），把所有文档都放进去。”

“当用户提问时，我们先用一个‘检索器’，根据问题去资料库里找到最相关的几段原文。然后，把用户的问题和我们找到的资料，一起打包发给LLM，对它说：‘嘿，参考这些材料，回答这个问题。’”

“这样一来，LLM就从一个‘闭卷考试’的考生，变成了一个‘开卷考试’的学霸。它回答的内容，就会严格基于我们提供的资料，大大减少了幻觉，也解决了私有知识的问题。”

“这个模式非常适合做企业知识库、智能客服、文档助手这类应用。”

**(切换PPT)**

---

#### **幻灯片 7: 模式二 - Function Calling：给模型一双“万能的手”**

*   **内容**: 一个流程图：用户说“查查天气” -> LLM识别意图，输出`{"tool": "query_weather", "city": "北京"}` -> 你的代码执行这个函数 -> 结果返回给LLM -> LLM生成自然语言回答。

**(讲者台词)**

“好，解决了知识问题，我们再来解决‘能力’问题：如何让模型有手有脚，能干活？”

“这就是**Function Calling**，函数调用。它的核心思想是，让LLM当一个‘**指挥官**’，而我们开发者，就是提供工具的‘军火库’。”

“整个流程是这样的：”

“第一步，我们先向LLM‘**注册**’我们的工具。比如，我写了一个查询天气的函数`query_weather(city)`，我会告诉LLM：‘我这里有个工具，叫`query_weather`，能查天气，需要一个城市名作为参数。’”

“第二步，当用户说‘帮我查查北京今天天气怎么样？’，LLM会**识别**出这个意图，它不会自己回答，而是会给我们返回一个结构化的指令，类似JSON：`{ "tool": "query_weather", "city": "北京" }`。”

“第三步，我们的应用程序拿到这个指令，就在**本地执行**我们自己写的`query_weather`函数，得到结果，比如‘晴，25度’。”

“最后，我们把这个结果再交还给LLM，它会用自然、流畅的语言，把结果‘**包装**’一下，回复给用户：‘北京今天天气晴朗，温度为25摄氏度。’”

“大家看，通过这个模式，模型就突破了虚拟世界的限制，可以调用任何我们提供的API，去查询数据库、订票、控制智能家居，真正地和外部世界互动起来了。”

**(切换PPT)**

---

#### **幻灯片 8: 演进 - Agent：当模型拥有“大脑”和“手脚”**

*   **内容**: 一个循环图：`思考 -> 行动(调用工具) -> 观察(得到结果) -> 再次思考...`

**(讲者台词)**

“当我们把RAG（知识）和Function Calling（工具）结合起来，再赋予模型一个‘思考和规划’的能力，一个更高级的概念就诞生了——**Agent**，智能体。”

“Agent不再是简单的一问一答，它能为了一个复杂目标，自主地制定计划、调用多个工具、并根据上一步的结果来调整下一步的行动。”

“比如你对它说：‘帮我规划一下明天去北京的出差行程，订好票，查好天气，然后把结果发邮件给我。’”

“一个Agent会这样做：”
1.  **思考**：嗯，这个任务需要分几步：查天气、订机票、写邮件。
2.  **行动**：调用`query_weather`工具。
3.  **观察**：得到天气结果“晴天”。
4.  **再次思考**：天气不错，可以订票了。
5.  **行动**：调用`book_flight`工具。
6.  **观察**：得到订票成功信息。
7.  **再次思考**：所有信息齐了，可以发邮件了。
8.  **行动**：调用`send_email`工具。
9.  **观察**：邮件发送成功，任务完成。

“这就是Agent的魅力。但随之而来也产生了一个新问题...”

**(切换PPT)**

---

#### **幻灯片 9: 未来 - MCP：AI世界的“普通话”**

*   **内容**: 左边是各种不同形状的插头（代表私有工具协议），右边是一个统一的USB-C接口（代表MCP）。

**(讲者台词)**

“问题就是，现在每个模型、每个框架，它们定义和调用工具的方式都不一样，就像是各种‘方言’。我为GPT写的工具，给Claude用可能就得改。这极大地阻碍了工具的复用和生态的发展。”

“想象一下，如果你的鼠标、键盘、充电器，每换一个牌子的电脑，接口就得换一次，那该多崩溃。”

“为了解决这个问题，**Model Context Protocol (MCP)** 应运而生。它的目标，就是成为AI工具领域的‘**普通话**’，或者说是‘**USB-C接口**’。”

“MCP是一个**标准化的开源协议**。它定义了一套统一的规范，让任何模型，都能方便地发现、理解和调用任何遵循这套规范的工具。”

“它的好处是显而易见的：**标准化、可复用、可组合**。开发者只需要写一次工具，就能接入到所有支持MCP的模型和应用中，极大地提升了开发效率。”

“比如我们内部的`eaip mcp`路由，就是基于这个理念，把企业内部五花八emen的API服务，统一封装成符合MCP标准的工具，让AI可以安全、高效地调用。”

**(切换PPT)**

---

#### **幻灯片 10: Demo演示**

*   **内容**: 屏幕录制或现场操作。

**(讲者台词)**

“说了这么多理论，我们来点实际的。接下来，我将现场演示一个非常简单的应用，它会通过MCP协议，让一个大语言模型调用一个我刚刚写的、用来查询今天日期的自定义工具。”

**(开始演示)**

1.  “首先，大家看，这是一个简单的MCP工具服务器，它暴露了一个叫`get_today_date`的工具。”
2.  “然后，在我们的客户端，我们不需要关心这个工具是怎么实现的，只需要连接到MCP服务器。”
3.  “现在，我向模型提问：‘今天几号？’。注意，模型本身是不知道实时日期的。”
4.  “看，模型通过MCP协议发现了`get_today_date`工具，并决定调用它。我们的服务器收到了调用请求，执行函数，并返回了今天的日期。”
5.  “最终，模型将结果格式化后，告诉我们‘今天是2025年10月16日’。”
6.  “这个过程，完美地展示了模型、协议、工具之间的协作。”

**(演示结束)**

---

#### **幻灯片 11: 总结与Q&A**

*   **内容**: 一条清晰的进化路径图：`LLM (核心) -> RAG (赋予知识) -> Function Calling (赋予工具) -> Agent (赋予大脑) -> MCP (赋予标准)`

**(讲者台词)**

“好了，我们来快速回顾一下今天的旅程。”

“我们从一个基础的**LLM**核心出发，它很聪明，但有局限。”
“通过**RAG**，我们给了它一本‘开卷考试’的书，解决了知识局限。”
“通过**Function Calling**，我们给了它一双‘万能的手’，解决了能力局限。”
“将两者结合，就进化成了能自主规划的**Agent**。”
“最后，为了让生态系统更有序、高效，我们引入了**MCP**，这门AI世界的‘普通话’。”

“对于我们开发者来说，我想传达的最重要的一点是：**AI应用开发的重点，已经从‘创造模型’转向了‘驾驭模型’**。我们的核心竞争力，在于如何巧妙地组合数据和工具，来创造出真正有价值的应用。”

“我的分享就到这里，谢谢大家。现在是Q&A时间，有什么问题欢迎提出。”
